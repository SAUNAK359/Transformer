{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":29550,"sourceType":"datasetVersion","datasetId":23079}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data & Preprocessing","metadata":{}},{"cell_type":"markdown","source":"# Dependencies","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torchvision.models import resnet50\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport glob\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-06T12:15:47.834145Z","iopub.execute_input":"2025-08-06T12:15:47.834962Z","iopub.status.idle":"2025-08-06T12:15:47.839123Z","shell.execute_reply.started":"2025-08-06T12:15:47.834929Z","shell.execute_reply":"2025-08-06T12:15:47.838230Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset Extraction","metadata":{}},{"cell_type":"code","source":"class ASLDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.samples = []\n\n        for label in sorted(os.listdir(root_dir)):\n            folder = os.path.join(root_dir, label)\n            if os.path.isdir(folder):\n                for img_path in glob.glob(os.path.join(folder, \"*.jpg\")):\n                    self.samples.append((img_path, label))\n\n        self.class_to_idx = {label: idx for idx, label in enumerate(sorted(os.listdir(root_dir)))}\n        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, self.class_to_idx[label]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T12:15:47.840264Z","iopub.execute_input":"2025-08-06T12:15:47.840524Z","iopub.status.idle":"2025-08-06T12:15:47.856277Z","shell.execute_reply.started":"2025-08-06T12:15:47.840500Z","shell.execute_reply":"2025-08-06T12:15:47.855622Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transformers","metadata":{}},{"cell_type":"code","source":"transform = T.Compose([\n    T.Resize((224, 224)),\n    T.RandomHorizontalFlip(),\n    T.ToTensor(),\n    T.Normalize([0.485, 0.456, 0.406], \n                [0.229, 0.224, 0.225])])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T12:15:47.857125Z","iopub.execute_input":"2025-08-06T12:15:47.857442Z","iopub.status.idle":"2025-08-06T12:15:47.870143Z","shell.execute_reply.started":"2025-08-06T12:15:47.857418Z","shell.execute_reply":"2025-08-06T12:15:47.869584Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DETR-style Encoder + Transformer Encoder","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision.models import resnet50\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=10000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        pos = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n        pe[:, 0::2] = torch.sin(pos * div_term)\n        pe[:, 1::2] = torch.cos(pos * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:x.size(0), :]\n        return x\n\nclass ASLTransformer(nn.Module):\n    def __init__(self, num_classes=29, d_model=512, nhead=8, num_layers=6):\n        super().__init__()\n        self.cnn_backbone = resnet50(pretrained=True)\n        self.cnn_backbone = nn.Sequential(*list(self.cnn_backbone.children())[:-2])  # (B, 2048, 7, 7)\n\n        self.input_proj = nn.Conv2d(2048, d_model, kernel_size=1)\n\n        self.pos_encoder = PositionalEncoding(d_model)\n        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n\n        self.classifier = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1, 1)),  # (B, 512, 1, 1)\n            nn.Flatten(),                  # (B, 512)\n            nn.LayerNorm(512),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        cnn_out = self.cnn_backbone(x)              # (B, 2048, 7, 7)\n        cnn_out = self.input_proj(cnn_out)          # (B, 512, 7, 7)\n\n        if not hasattr(self, \"_printed_debug\"):\n            print(\"CNN shape:\", cnn_out.shape)\n            flat_x = cnn_out.flatten(2).permute(0, 2, 1)\n            print(\"Transformer input:\", flat_x.shape)\n            self._printed_debug = True\n\n        x = cnn_out.flatten(2).permute(0, 2, 1)     # (B, 49, 512)\n        x = self.pos_encoder(x)                     # (B, 49, 512)\n        x = self.transformer(x)                     # (B, 49, 512)\n\n        x = x.permute(0, 2, 1).view(batch_size, 512, 7, 7)  # (B, 512, 7, 7)\n        out = self.classifier(x)                    # (B, num_classes)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T12:15:47.871529Z","iopub.execute_input":"2025-08-06T12:15:47.871723Z","iopub.status.idle":"2025-08-06T12:15:47.889067Z","shell.execute_reply.started":"2025-08-06T12:15:47.871708Z","shell.execute_reply":"2025-08-06T12:15:47.888539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Script","metadata":{}},{"cell_type":"code","source":"def train(model, train_loader, val_loader, device, epochs=10):\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n    criterion = nn.CrossEntropyLoss()\n    scaler = torch.cuda.amp.GradScaler()  # for mixed precision\n\n    model.to(device)\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        correct = 0\n        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            with torch.cuda.amp.autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            total_loss += loss.item()\n            preds = outputs.argmax(dim=1)\n            correct += (preds == labels).sum().item()\n\n        acc = correct / len(train_loader.dataset)\n        print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f} - Acc: {acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T12:15:47.889738Z","iopub.execute_input":"2025-08-06T12:15:47.889979Z","iopub.status.idle":"2025-08-06T12:15:47.904810Z","shell.execute_reply.started":"2025-08-06T12:15:47.889955Z","shell.execute_reply":"2025-08-06T12:15:47.904216Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Dump & Training Call","metadata":{}},{"cell_type":"markdown","source":"While calling the path, it is found that the dataset has 1 extra folder which results in invalid directory error. It is advised to avoid more complexity just add the secondary folder from train , test sub folders of the dataset","metadata":{}},{"cell_type":"code","source":"import os\n\ntrain_path = \"/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train\"\nprint(\"Classes found:\", os.listdir(train_path))\nprint(\"Images in 'A':\", os.listdir(os.path.join(train_path, \"A\"))[:5])  # Should list A1.jpg etc.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T12:15:47.905408Z","iopub.execute_input":"2025-08-06T12:15:47.905564Z","iopub.status.idle":"2025-08-06T12:15:47.931749Z","shell.execute_reply.started":"2025-08-06T12:15:47.905551Z","shell.execute_reply":"2025-08-06T12:15:47.931246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = ASLDataset(\"/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train\", transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nmodel = ASLTransformer(num_classes=29)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain(model, train_loader, None, device, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T12:15:47.932335Z","iopub.execute_input":"2025-08-06T12:15:47.932526Z","iopub.status.idle":"2025-08-06T13:01:37.518551Z","shell.execute_reply.started":"2025-08-06T12:15:47.932511Z","shell.execute_reply":"2025-08-06T13:01:37.517611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimg = Image.open(\"/kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/A_test.jpg\")\nimg = transform(img).unsqueeze(0).to(device)\nmodel.eval()\nwith torch.no_grad():\n    output = model(img)\n    pred_class = torch.argmax(output, dim=1).item()\n\nprint(f\"Predicted class: {train_dataset.idx_to_class[pred_class]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T13:05:52.888967Z","iopub.execute_input":"2025-08-06T13:05:52.889739Z","iopub.status.idle":"2025-08-06T13:05:53.027601Z","shell.execute_reply.started":"2025-08-06T13:05:52.889710Z","shell.execute_reply":"2025-08-06T13:05:53.027013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}